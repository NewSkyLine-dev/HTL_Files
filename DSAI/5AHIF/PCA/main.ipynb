{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f25b92",
   "metadata": {},
   "source": [
    "# PCA\n",
    "\n",
    "- Fabian Oppermann\n",
    "- Petruta-Denisa Biholari\n",
    "- Philipp Hasel\n",
    "\n",
    "https://www.kaggle.com/datasets/nelgiriyewithana/most-streamed-spotify-songs-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6014d0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas matplotlib scikit-learn sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2bab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./Most Streamed Spotify Songs 2024.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecb7bd0",
   "metadata": {},
   "source": [
    "# 1. Datenbereinigung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667c345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "\n",
    "# Fehlende Werte analysieren\n",
    "missing = df.isnull().sum()\n",
    "print(\"Fehlende Werte pro Spalte vor weiterer Bereinigung:\")\n",
    "print(missing[missing > 0])\n",
    "\n",
    "df = df.dropna(subset=['Spotify Streams', 'TikTok Posts', 'Spotify Popularity'])\n",
    "\n",
    "df = df.drop(columns=[\"TIDAL Popularity\"])\n",
    "\n",
    "df = df.drop(columns=['Track', 'Album Name', 'ISRC'])\n",
    "\n",
    "# Datei speichern\n",
    "df.to_csv(\"korr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf4c53f",
   "metadata": {},
   "source": [
    "# 2. kNN und PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1ef259",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Numerische Spalten identifizieren, die als Objekt-Typ geladen wurden und Kommas enthalten könnten\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == object:\n",
    "        # Versuch, Kommas zu entfernen und in numerischen Typ umzuwandeln\n",
    "        # Behält Spalten, die nicht numerisch sind (z.B. 'Artist', 'Release Date'), als Objekt\n",
    "        try:\n",
    "            # Teste, ob nach dem Ersetzen von Kommas eine Umwandlung in float möglich ist\n",
    "            pd.to_numeric(df[col].str.replace(',', '', regex=False))\n",
    "            df[col] = df[col].str.replace(',', '', regex=False).astype(float)\n",
    "            print(f\"Spalte '{col}' wurde zu float konvertiert.\")\n",
    "        except ValueError:\n",
    "            # Wenn die Umwandlung fehlschlägt, ist es wahrscheinlich eine echte Zeichenkette\n",
    "            print(f\"Spalte '{col}' konnte nicht zu float konvertiert werden und bleibt Objekt.\")\n",
    "        except AttributeError: # Falls .str nicht verfügbar ist (z.B. wenn es bereits numerisch ist, aber als Objekt)\n",
    "             try:\n",
    "                df[col] = pd.to_numeric(df[col])\n",
    "                print(f\"Spalte '{col}' (ursprünglich Objekt) wurde zu numerisch konvertiert.\")\n",
    "             except ValueError:\n",
    "                print(f\"Spalte '{col}' (ursprünglich Objekt) konnte nicht zu numerisch konvertiert werden.\")\n",
    "\n",
    "\n",
    "# Zielvariable PopularityClass erstellen mit pd.cut (konsistent)\n",
    "# Die Bins sollten die gesamte mögliche Range von Spotify Popularity abdecken (typischerweise 0-100)\n",
    "df['PopularityClass'] = pd.cut(df['Spotify Popularity'], \n",
    "                                bins=[-1, 40, 70, 101], # Anpassung der oberen Grenze auf 101 (oder df['Spotify Popularity'].max() + 1)\n",
    "                                labels=['Low', 'Medium', 'High'], \n",
    "                                right=True) # right=True bedeutet, dass der rechte Bin-Rand inklusive ist\n",
    "\n",
    "\n",
    "if df['PopularityClass'].isnull().any():\n",
    "    print(\"Warnung: Es gibt NaN-Werte in 'PopularityClass' nach pd.cut. Überprüfen Sie die Bins und Werte in 'Spotify Popularity'.\")\n",
    "    print(df[df['PopularityClass'].isnull()]['Spotify Popularity'])\n",
    "    # Optionale Behandlung: df.dropna(subset=['PopularityClass'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "non_features = ['Artist', 'Release Date', 'Explicit Track', 'Spotify Popularity', 'PopularityClass']\n",
    "X = df.drop(columns=non_features, errors='ignore') # errors='ignore' falls eine Spalte schon fehlt\n",
    "y = df['PopularityClass'].dropna() # Sicherstellen, dass y keine NaNs hat, falls welche durch pd.cut entstanden\n",
    "X = X.loc[y.index] # X und y synchron halten\n",
    "\n",
    "# Kategoriale und numerische Features für den Preprocessor identifizieren\n",
    "num_features = X.select_dtypes(include=np.number).columns\n",
    "cat_features = X.select_dtypes(include=['object', 'bool']).columns # Bool hier auch als cat behandelt für OneHotEncoding\n",
    "\n",
    "# Labels in Zahlen umwandeln für y\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Daten splitten\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)\n",
    "\n",
    "# Preprocessing Pipelines\n",
    "# Numerische Pipeline: Fehlende Werte mit Median füllen (robuster gegen Ausreißer als Mittelwert) & skalieren\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")), # Geändert zu Median für Konsistenz und Robustheit\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Kategoriale Pipeline: Fehlende Werte mit häufigstem Wert füllen & OneHot kodieren\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# ColumnTransformer, um Pipelines auf die richtigen Spalten anzuwenden\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_features),\n",
    "    (\"cat\", cat_pipeline, cat_features)\n",
    "])\n",
    "\n",
    "# Besten Modelle laut Grid-Search:\n",
    "\"\"\"\n",
    "--- Random Forest ---\n",
    "Beste Parameter: {'classifier__max_depth': None, 'classifier__n_estimators': 50}\n",
    "Laufzeit: 1.64 Sekunden\n",
    "Bestes CV-Score (Accuracy): 0.8155\n",
    "\n",
    "--- KNN ---\n",
    "Beste Parameter: {'classifier__n_neighbors': 7, 'classifier__weights': 'distance'}\n",
    "Laufzeit: 0.13 Sekunden\n",
    "Bestes CV-Score (Accuracy): 0.7704\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1adcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "random_forest_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", RandomForestClassifier(n_estimators=50, max_depth=None, random_state=42))\n",
    "])\n",
    "\n",
    "knn_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", KNeighborsClassifier(n_neighbors=7, weights='distance'))\n",
    "])\n",
    "\n",
    "# Modelle trainieren\n",
    "random_forest_pipeline.fit(X_train, y_train)\n",
    "knn_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Modelle evaluieren\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "models = {\n",
    "    \"Random Forest\": random_forest_pipeline,\n",
    "    \"kNN\": knn_pipeline\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    y_pred = model.predict(X_val)\n",
    "    print(classification_report(y_val, y_pred, target_names=le.classes_))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
